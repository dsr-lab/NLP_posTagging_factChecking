{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment1",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRJJ4tzaC852"
      },
      "source": [
        "# Preliminary Steps\n",
        "These are some preliminary steps before addressing the task. Import some basic libraries and set a variable that will be used in multiple steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTCTmlk1C0Sm"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vspH9UzptOFT"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElPThN5GWAZl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsjdOVHZtSnp"
      },
      "source": [
        "## Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR9RtRITt72b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJbpdftCt8Gl"
      },
      "source": [
        "## Train, validation and test splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXgbC4TAuJ81"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Co7hfK2uKD8"
      },
      "source": [
        "# GloVe "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tRukt6Kxx4R"
      },
      "source": [
        "## OOV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-uwA9DYuNtr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MypraiXCuOIb"
      },
      "source": [
        "# Models\n",
        "This section is used for creating different models, going from a baseline to slightly more complicated ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7EPmCLyuZVB"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpzIuGZzWnbB"
      },
      "source": [
        "https://stackoverflow.com/questions/61361866/dense-vs-timedistributeddense\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V__iSg0qcABw"
      },
      "source": [
        "# TODO: all the following constants are temporary \n",
        "N_CLASSES = 20  # this must be equal to the number of tags\n",
        "VOCABULARY_SIZE = 1000  # this must be obtained from the dataset\n",
        "EMBEDDING_SIZE = 64  # hyper-parameter to properly set\n",
        "MAX_SEQUENCE_SIZE = 100  # this must be obtained from the dataset\n",
        "BATCH_SIZE = 128  # hyper-parameter to properly set"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE7Mvm9sZ8Pf"
      },
      "source": [
        "def create_model(layers) -> keras.Model:\n",
        "    \"\"\"\n",
        "    Compute the NAIVE version of the convolution.\n",
        "    After the creation, the model is compiled and its summary is printed \n",
        "    to console.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    layers : array\n",
        "        Array that contains a list of layers that must be added \n",
        "        to the model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : keras.Model\n",
        "        The keras model\n",
        "    \"\"\"\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    for idx, layer in enumerate(layers):\n",
        "\n",
        "        # Sanity checks for being sure that the last layer has been \n",
        "        # correctly set\n",
        "        if idx == len(layers) - 1:\n",
        "            assert layer.activation == keras.activations.softmax, 'Wrong activation function'\n",
        "            assert layer.units == N_CLASSES, 'Wrong number of units'\n",
        "\n",
        "        model.add(layer)\n",
        "\n",
        "    # Compile\n",
        "    model.compile(**compile_info)\n",
        "\n",
        "    # Print model summary\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqZ-XwiJT76C"
      },
      "source": [
        "# This tensor should contain the weights obtained by GloVe\n",
        "embedding_weights = tf.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))\n",
        "\n",
        "def baseline_model(compile_info, embedding_weights = None) -> keras.Model:\n",
        "\n",
        "    model_layers = []\n",
        "\n",
        "    model_layers.append(\n",
        "        layers.Embedding(\n",
        "            input_dim=VOCABULARY_SIZE, \n",
        "            output_dim=EMBEDDING_SIZE, \n",
        "            input_length=SEQUENCE_SIZE,\n",
        "            weights=[embedding_weights],\n",
        "            mask_zero=True\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    # TODO: try different activation functions??\n",
        "    # LSTM layer\n",
        "    model_layers.append(\n",
        "        layers.LSTM(128, return_sequences=True, activation='relu')\n",
        "        )\n",
        "\n",
        "    # Dense layer\n",
        "    model_layers.append(\n",
        "        layers.Dense(N_CLASSES, activation='softmax')\n",
        "        )\n",
        "\n",
        "    # Create the model\n",
        "    model = create_model(model_layers)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_S2EqCZkA60",
        "outputId": "e5ac5fb2-512b-4b93-ca04-144cf077b37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use sparse_categorical_crossentropy because labels are one hot encoded\n",
        "compile_info = {\n",
        "    'optimizer': keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    'loss': 'sparse_categorical_crossentropy',\n",
        "    'metrics': [keras.metrics.SparseCategoricalAccuracy()],\n",
        "}\n",
        "\n",
        "model_1 = baseline_model(compile_info, embedding_weights)\n",
        "\n",
        "\n",
        "# Create a random input tensor for testing the model\n",
        "# The input tensor should be the result\n",
        "input_tensor = tf.random.uniform((BATCH_SIZE, SEQUENCE_SIZE))\n",
        "print(f'Input tensor shape: {input_tensor.shape}')\n",
        "output_tensor = model_1(input_tensor)\n",
        "print(f'Output tensor shape: {output_tensor.shape}')\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_42 (Embedding)    (None, 100, 64)           64000     \n",
            "                                                                 \n",
            " lstm_41 (LSTM)              (None, 100, 128)          98816     \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 100, 20)           2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 165,396\n",
            "Trainable params: 165,396\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Input tensor shape: (128, 100)\n",
            "Output tensor shape: (128, 100, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4l5n888vLql"
      },
      "source": [
        "## Baseline variations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMvk3AQFukOh"
      },
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9We6j_USupzN"
      },
      "source": [
        "### Additional LSTM layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RN6ySWyu13J"
      },
      "source": [
        "### Additional Dense layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwOShFdwvaHN"
      },
      "source": [
        "# Training and Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1SYhjS1vvzF"
      },
      "source": [
        "# Disussion and Error Analysis"
      ]
    }
  ]
}